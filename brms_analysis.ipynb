{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "Loading required package: ggplot2\n",
      "Loading 'brms' package (version 2.4.0). Useful instructions\n",
      "can be found by typing help('brms'). A more detailed introduction\n",
      "to the package is available through vignette('brms_overview').\n",
      "Run theme_set(theme_default()) to use the default bayesplot theme.\n"
     ]
    }
   ],
   "source": [
    "library(brms)\n",
    "theme_set(theme_default())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load RData into environment object (\"ex\")\n",
    "load(\"./prepped_data.RData\", ex <- new.env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from environment.\n",
    "# For testing, we're using df_slice, which has only subjects 1 an 2.\n",
    "df <- ex$df_slice\n",
    "#df <- ex$df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Answer</th><th scope=col>Block</th><th scope=col>CD</th><th scope=col>Choice</th><th scope=col>ED</th><th scope=col>RT</th><th scope=col>Trlnum</th><th scope=col>conNT</th><th scope=col>conNT_cent</th><th scope=col>item_id</th><th scope=col>newNT</th><th scope=col>newNT_cent</th><th scope=col>sub</th><th scope=col>task</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1           </td><td>0           </td><td>1.1409781   </td><td>0           </td><td>15.32376    </td><td>1.762020    </td><td> 0          </td><td>8.711341    </td><td>-0.02945527 </td><td>16.0        </td><td>6.996014    </td><td> 0.002536885</td><td>1           </td><td>disc        </td></tr>\n",
       "\t<tr><td>0           </td><td>1           </td><td>1.1409781   </td><td>1           </td><td>15.32376    </td><td>2.242939    </td><td>33          </td><td>8.711341    </td><td>-0.02945527 </td><td>16.0        </td><td>6.996014    </td><td> 0.002536885</td><td>1           </td><td>disc        </td></tr>\n",
       "\t<tr><td>1           </td><td>2           </td><td>1.1409781   </td><td>0           </td><td>15.32376    </td><td>1.766368    </td><td>39          </td><td>8.711341    </td><td>-0.02945527 </td><td>16.0        </td><td>6.996014    </td><td> 0.002536885</td><td>1           </td><td>disc        </td></tr>\n",
       "\t<tr><td>1           </td><td>0           </td><td>1.1409781   </td><td>0           </td><td>15.32376    </td><td>2.559490    </td><td>38          </td><td>8.711341    </td><td>-0.02945527 </td><td>16.0        </td><td>6.996014    </td><td> 0.002536885</td><td>2           </td><td>disc        </td></tr>\n",
       "\t<tr><td>1           </td><td>2           </td><td>1.1409781   </td><td>0           </td><td>15.32376    </td><td>2.417423    </td><td>51          </td><td>8.711341    </td><td>-0.02945527 </td><td>16.0        </td><td>6.996014    </td><td> 0.002536885</td><td>2           </td><td>disc        </td></tr>\n",
       "\t<tr><td>0           </td><td>1           </td><td>0.7320226   </td><td>3           </td><td>14.63461    </td><td>2.492440    </td><td>11          </td><td>8.747425    </td><td> 0.00662891 </td><td>62.0        </td><td>6.990727    </td><td>-0.002750086</td><td>1           </td><td>disc        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " Answer & Block & CD & Choice & ED & RT & Trlnum & conNT & conNT\\_cent & item\\_id & newNT & newNT\\_cent & sub & task\\\\\n",
       "\\hline\n",
       "\t 1            & 0            & 1.1409781    & 0            & 15.32376     & 1.762020     &  0           & 8.711341     & -0.02945527  & 16.0         & 6.996014     &  0.002536885 & 1            & disc        \\\\\n",
       "\t 0            & 1            & 1.1409781    & 1            & 15.32376     & 2.242939     & 33           & 8.711341     & -0.02945527  & 16.0         & 6.996014     &  0.002536885 & 1            & disc        \\\\\n",
       "\t 1            & 2            & 1.1409781    & 0            & 15.32376     & 1.766368     & 39           & 8.711341     & -0.02945527  & 16.0         & 6.996014     &  0.002536885 & 1            & disc        \\\\\n",
       "\t 1            & 0            & 1.1409781    & 0            & 15.32376     & 2.559490     & 38           & 8.711341     & -0.02945527  & 16.0         & 6.996014     &  0.002536885 & 2            & disc        \\\\\n",
       "\t 1            & 2            & 1.1409781    & 0            & 15.32376     & 2.417423     & 51           & 8.711341     & -0.02945527  & 16.0         & 6.996014     &  0.002536885 & 2            & disc        \\\\\n",
       "\t 0            & 1            & 0.7320226    & 3            & 14.63461     & 2.492440     & 11           & 8.747425     &  0.00662891  & 62.0         & 6.990727     & -0.002750086 & 1            & disc        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Answer | Block | CD | Choice | ED | RT | Trlnum | conNT | conNT_cent | item_id | newNT | newNT_cent | sub | task | \n",
       "|---|---|---|---|---|---|\n",
       "| 1            | 0            | 1.1409781    | 0            | 15.32376     | 1.762020     |  0           | 8.711341     | -0.02945527  | 16.0         | 6.996014     |  0.002536885 | 1            | disc         | \n",
       "| 0            | 1            | 1.1409781    | 1            | 15.32376     | 2.242939     | 33           | 8.711341     | -0.02945527  | 16.0         | 6.996014     |  0.002536885 | 1            | disc         | \n",
       "| 1            | 2            | 1.1409781    | 0            | 15.32376     | 1.766368     | 39           | 8.711341     | -0.02945527  | 16.0         | 6.996014     |  0.002536885 | 1            | disc         | \n",
       "| 1            | 0            | 1.1409781    | 0            | 15.32376     | 2.559490     | 38           | 8.711341     | -0.02945527  | 16.0         | 6.996014     |  0.002536885 | 2            | disc         | \n",
       "| 1            | 2            | 1.1409781    | 0            | 15.32376     | 2.417423     | 51           | 8.711341     | -0.02945527  | 16.0         | 6.996014     |  0.002536885 | 2            | disc         | \n",
       "| 0            | 1            | 0.7320226    | 3            | 14.63461     | 2.492440     | 11           | 8.747425     |  0.00662891  | 62.0         | 6.990727     | -0.002750086 | 1            | disc         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Answer Block CD        Choice ED       RT       Trlnum conNT    conNT_cent \n",
       "1 1      0     1.1409781 0      15.32376 1.762020  0     8.711341 -0.02945527\n",
       "2 0      1     1.1409781 1      15.32376 2.242939 33     8.711341 -0.02945527\n",
       "3 1      2     1.1409781 0      15.32376 1.766368 39     8.711341 -0.02945527\n",
       "4 1      0     1.1409781 0      15.32376 2.559490 38     8.711341 -0.02945527\n",
       "5 1      2     1.1409781 0      15.32376 2.417423 51     8.711341 -0.02945527\n",
       "6 0      1     0.7320226 3      14.63461 2.492440 11     8.747425  0.00662891\n",
       "  item_id newNT    newNT_cent   sub task\n",
       "1 16.0    6.996014  0.002536885 1   disc\n",
       "2 16.0    6.996014  0.002536885 1   disc\n",
       "3 16.0    6.996014  0.002536885 1   disc\n",
       "4 16.0    6.996014  0.002536885 2   disc\n",
       "5 16.0    6.996014  0.002536885 2   disc\n",
       "6 62.0    6.990727 -0.002750086 1   disc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t623 obs. of  14 variables:\n",
      " $ Answer    : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 2 1 2 2 1 1 ...\n",
      " $ Block     : Factor w/ 3 levels \"0\",\"1\",\"2\": 1 2 3 1 3 2 3 3 1 2 ...\n",
      " $ CD        : num  1.14 1.14 1.14 1.14 1.14 ...\n",
      " $ Choice    : int  0 1 0 0 0 3 0 0 1 2 ...\n",
      " $ ED        : num  15.3 15.3 15.3 15.3 15.3 ...\n",
      " $ RT        : num  1.76 2.24 1.77 2.56 2.42 ...\n",
      " $ Trlnum    : int  0 33 39 38 51 11 63 40 2 31 ...\n",
      " $ conNT     : num  8.71 8.71 8.71 8.71 8.71 ...\n",
      " $ conNT_cent: num  -0.0295 -0.0295 -0.0295 -0.0295 -0.0295 ...\n",
      " $ item_id   : Factor w/ 64 levels \"0.0\",\"1.0\",\"10.0\",..: 9 9 9 9 9 60 60 60 63 63 ...\n",
      " $ newNT     : num  7 7 7 7 7 ...\n",
      " $ newNT_cent: num  0.00254 0.00254 0.00254 0.00254 0.00254 ...\n",
      " $ sub       : Factor w/ 2 levels \"1\",\"2\": 1 1 1 2 2 1 1 2 1 1 ...\n",
      " $ task      : Factor w/ 2 levels \"disc\",\"name\": 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "## Overview\n",
    "\n",
    "We want to predict accuracy (\"Answer\") by the following:\n",
    "- Random effects structure:\n",
    "    - $(Block*NT|sub) + (1|item) + (1|task)$\n",
    "    - Although we might also want to compare with a varying slope for task over subjects\n",
    "- Fixed effects structure:\n",
    "    - $NT*Block$\n",
    "    - NT can be: conNT, newNT, conNT AND newNT (incremental prediction)\n",
    "    - $H_0$: Model without NT\n",
    "    - We'll use the centered version of the neural typicality measures for interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a null model, which assumes full random effects structure and a fixed effect for learning across blocks,\n",
    "# but no influence of any neural typicality measure.\n",
    "answer_nullmodel <- brm(Answer ~ Block + (Block|sub) + (1|item_id) + (1|task),\n",
    "                        data = df,\n",
    "                        family = bernoulli,\n",
    "                        file = \"answer_nullmodel\",\n",
    "                        chains = 2, cores = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(answer_nullmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newfound neural typicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the newfound neural typicality measure to the model\n",
    "answer_newNT <- brm(Answer ~ newNT_cent*Block + (newNT_cent*Block|sub) + (1|item_id) + (1|task),\n",
    "                    data = df,\n",
    "                    family = bernoulli,\n",
    "                    file = \"answer_newNT\",\n",
    "                    chains = 2, cores = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“There were 19 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help.\n",
      "See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup”"
     ]
    },
    {
     "data": {
      "text/plain": [
       " Family: bernoulli \n",
       "  Links: mu = logit \n",
       "Formula: Answer ~ newNT_cent * Block + (newNT_cent * Block | sub) + (1 | item_id) + (1 | task) \n",
       "   Data: df_slice (Number of observations: 623) \n",
       "Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n",
       "         total post-warmup samples = 2000\n",
       "\n",
       "Group-Level Effects: \n",
       "~item_id (Number of levels: 64) \n",
       "              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "sd(Intercept)     1.32      0.21     0.99     1.81        248 1.00\n",
       "\n",
       "~sub (Number of levels: 2) \n",
       "                                         Estimate Est.Error l-95% CI u-95% CI\n",
       "sd(Intercept)                                3.54      5.02     0.05    20.46\n",
       "sd(newNT_cent)                               9.90      9.97     0.34    36.38\n",
       "sd(Block1)                                   3.54      5.01     0.03    17.24\n",
       "sd(Block2)                                   3.11      4.49     0.04    14.52\n",
       "sd(newNT_cent:Block1)                       10.43     11.35     0.26    38.06\n",
       "sd(newNT_cent:Block2)                       13.35     41.73     0.38    42.61\n",
       "cor(Intercept,newNT_cent)                   -0.02      0.40    -0.76     0.70\n",
       "cor(Intercept,Block1)                        0.00      0.39    -0.73     0.72\n",
       "cor(newNT_cent,Block1)                      -0.01      0.36    -0.67     0.68\n",
       "cor(Intercept,Block2)                       -0.01      0.39    -0.73     0.72\n",
       "cor(newNT_cent,Block2)                      -0.01      0.38    -0.72     0.70\n",
       "cor(Block1,Block2)                           0.06      0.42    -0.74     0.79\n",
       "cor(Intercept,newNT_cent:Block1)             0.02      0.36    -0.67     0.69\n",
       "cor(newNT_cent,newNT_cent:Block1)           -0.02      0.37    -0.72     0.73\n",
       "cor(Block1,newNT_cent:Block1)                0.00      0.36    -0.67     0.69\n",
       "cor(Block2,newNT_cent:Block1)               -0.02      0.38    -0.71     0.70\n",
       "cor(Intercept,newNT_cent:Block2)            -0.02      0.38    -0.70     0.68\n",
       "cor(newNT_cent,newNT_cent:Block2)            0.03      0.38    -0.67     0.72\n",
       "cor(Block1,newNT_cent:Block2)               -0.02      0.39    -0.71     0.73\n",
       "cor(Block2,newNT_cent:Block2)               -0.02      0.38    -0.69     0.70\n",
       "cor(newNT_cent:Block1,newNT_cent:Block2)    -0.01      0.38    -0.71     0.70\n",
       "                                         Eff.Sample Rhat\n",
       "sd(Intercept)                                    38 1.06\n",
       "sd(newNT_cent)                                 2000 1.00\n",
       "sd(Block1)                                      159 1.00\n",
       "sd(Block2)                                      288 1.01\n",
       "sd(newNT_cent:Block1)                          2000 1.00\n",
       "sd(newNT_cent:Block2)                           418 1.00\n",
       "cor(Intercept,newNT_cent)                       131 1.01\n",
       "cor(Intercept,Block1)                          1275 1.00\n",
       "cor(newNT_cent,Block1)                          646 1.00\n",
       "cor(Intercept,Block2)                          1535 1.00\n",
       "cor(newNT_cent,Block2)                          722 1.01\n",
       "cor(Block1,Block2)                              120 1.01\n",
       "cor(Intercept,newNT_cent:Block1)               2000 1.01\n",
       "cor(newNT_cent,newNT_cent:Block1)              1510 1.00\n",
       "cor(Block1,newNT_cent:Block1)                  1357 1.00\n",
       "cor(Block2,newNT_cent:Block1)                  1339 1.00\n",
       "cor(Intercept,newNT_cent:Block2)               2000 1.01\n",
       "cor(newNT_cent,newNT_cent:Block2)               745 1.00\n",
       "cor(Block1,newNT_cent:Block2)                   236 1.00\n",
       "cor(Block2,newNT_cent:Block2)                   422 1.01\n",
       "cor(newNT_cent:Block1,newNT_cent:Block2)        901 1.00\n",
       "\n",
       "~task (Number of levels: 2) \n",
       "              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "sd(Intercept)     3.96      4.00     0.36    14.96        210 1.02\n",
       "\n",
       "Population-Level Effects: \n",
       "                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "Intercept             0.41      3.91    -7.40     8.80        127 1.00\n",
       "newNT_cent         -119.97     77.22  -274.86    31.55        412 1.01\n",
       "Block1               -0.15      4.27    -8.87     9.39        124 1.01\n",
       "Block2               -0.08      4.01   -13.23     8.60         48 1.05\n",
       "newNT_cent:Block1    40.13     77.18  -105.40   192.66        361 1.00\n",
       "newNT_cent:Block2    58.34     83.80   -87.08   218.95        532 1.00\n",
       "\n",
       "Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample \n",
       "is a crude measure of effective sample size, and Rhat is the potential \n",
       "scale reduction factor on split chains (at convergence, Rhat = 1)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(answer_newNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conserved neural typicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_conNT <- brm(Answer ~ conNT_cent*Block + (conNT_cent*Block|sub) + (1|item_id) + (1|task),\n",
    "                    data = df,\n",
    "                    family = bernoulli,\n",
    "                    file = \"answer_conNT\",\n",
    "                    chains = 2, cores = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“There were 18 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help.\n",
      "See http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup”"
     ]
    },
    {
     "data": {
      "text/plain": [
       " Family: bernoulli \n",
       "  Links: mu = logit \n",
       "Formula: Answer ~ conNT_cent * Block + (conNT_cent * Block | sub) + (1 | item_id) + (1 | task) \n",
       "   Data: df (Number of observations: 623) \n",
       "Samples: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n",
       "         total post-warmup samples = 2000\n",
       "\n",
       "Group-Level Effects: \n",
       "~item_id (Number of levels: 64) \n",
       "              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "sd(Intercept)     1.37      0.21     0.99     1.84        448 1.00\n",
       "\n",
       "~sub (Number of levels: 2) \n",
       "                                         Estimate Est.Error l-95% CI u-95% CI\n",
       "sd(Intercept)                                2.59      3.48     0.04    12.90\n",
       "sd(conNT_cent)                               6.16      6.39     0.18    23.22\n",
       "sd(Block1)                                   2.88      4.03     0.04    13.61\n",
       "sd(Block2)                                   2.99      4.48     0.04    14.80\n",
       "sd(conNT_cent:Block1)                        8.03      7.09     0.38    26.32\n",
       "sd(conNT_cent:Block2)                        7.73      7.97     0.16    26.62\n",
       "cor(Intercept,conNT_cent)                    0.00      0.38    -0.71     0.70\n",
       "cor(Intercept,Block1)                       -0.02      0.40    -0.74     0.72\n",
       "cor(conNT_cent,Block1)                       0.01      0.39    -0.75     0.72\n",
       "cor(Intercept,Block2)                       -0.00      0.38    -0.70     0.72\n",
       "cor(conNT_cent,Block2)                      -0.01      0.38    -0.72     0.73\n",
       "cor(Block1,Block2)                          -0.00      0.40    -0.71     0.71\n",
       "cor(Intercept,conNT_cent:Block1)            -0.02      0.38    -0.73     0.73\n",
       "cor(conNT_cent,conNT_cent:Block1)           -0.03      0.38    -0.72     0.67\n",
       "cor(Block1,conNT_cent:Block1)               -0.02      0.38    -0.73     0.70\n",
       "cor(Block2,conNT_cent:Block1)               -0.00      0.38    -0.67     0.71\n",
       "cor(Intercept,conNT_cent:Block2)            -0.02      0.38    -0.73     0.70\n",
       "cor(conNT_cent,conNT_cent:Block2)           -0.01      0.38    -0.73     0.70\n",
       "cor(Block1,conNT_cent:Block2)               -0.01      0.38    -0.72     0.69\n",
       "cor(Block2,conNT_cent:Block2)                0.00      0.38    -0.68     0.71\n",
       "cor(conNT_cent:Block1,conNT_cent:Block2)     0.04      0.38    -0.67     0.72\n",
       "                                         Eff.Sample Rhat\n",
       "sd(Intercept)                                   615 1.00\n",
       "sd(conNT_cent)                                 1471 1.00\n",
       "sd(Block1)                                      588 1.00\n",
       "sd(Block2)                                      469 1.00\n",
       "sd(conNT_cent:Block1)                           517 1.01\n",
       "sd(conNT_cent:Block2)                          1014 1.00\n",
       "cor(Intercept,conNT_cent)                      2000 1.00\n",
       "cor(Intercept,Block1)                          2000 1.00\n",
       "cor(conNT_cent,Block1)                         1430 1.00\n",
       "cor(Intercept,Block2)                          1513 1.00\n",
       "cor(conNT_cent,Block2)                         1713 1.00\n",
       "cor(Block1,Block2)                             1590 1.00\n",
       "cor(Intercept,conNT_cent:Block1)               2000 1.00\n",
       "cor(conNT_cent,conNT_cent:Block1)              1692 1.00\n",
       "cor(Block1,conNT_cent:Block1)                  1414 1.00\n",
       "cor(Block2,conNT_cent:Block1)                  1388 1.00\n",
       "cor(Intercept,conNT_cent:Block2)               2000 1.00\n",
       "cor(conNT_cent,conNT_cent:Block2)              2000 1.00\n",
       "cor(Block1,conNT_cent:Block2)                  1669 1.00\n",
       "cor(Block2,conNT_cent:Block2)                  1463 1.00\n",
       "cor(conNT_cent:Block1,conNT_cent:Block2)       1271 1.00\n",
       "\n",
       "~task (Number of levels: 2) \n",
       "              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "sd(Intercept)     3.62      3.85     0.33    14.57        749 1.00\n",
       "\n",
       "Population-Level Effects: \n",
       "                  Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat\n",
       "Intercept             1.20      3.84    -6.06    10.00        396 1.00\n",
       "conNT_cent            6.17      6.94    -8.09    20.47        325 1.01\n",
       "Block1               -0.54      2.97    -7.20     5.69        280 1.01\n",
       "Block2                0.27      2.78    -5.41     7.19        303 1.01\n",
       "conNT_cent:Block1    -3.63      8.61   -20.19    13.54        532 1.00\n",
       "conNT_cent:Block2    -2.34      8.49   -19.45    14.32        766 1.00\n",
       "\n",
       "Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample \n",
       "is a crude measure of effective sample size, and Rhat is the potential \n",
       "scale reduction factor on split chains (at convergence, Rhat = 1)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(answer_conNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newfound *AND* conserved typicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_bothNT <- brm(Answer ~ conNT_cent*newNT_cent*Block + (conNT_cent*newNT_cent*Block|sub) + (1|item_id) + (1|task),\n",
    "                    data = df,\n",
    "                    family = bernoulli,\n",
    "                    file = \"answer_bothNT\",\n",
    "                    chains = 2, cores = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(answer_bothNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                  LOOIC    SE\n",
       "answer_conNT                     711.16 24.20\n",
       "answer_newNT                     712.88 24.63\n",
       "answer_bothNT                    723.96 26.55\n",
       "answer_nullmodel                 704.35 23.56\n",
       "answer_conNT - answer_newNT       -1.72  4.18\n",
       "answer_conNT - answer_bothNT     -12.81  5.80\n",
       "answer_conNT - answer_nullmodel    6.81  2.87\n",
       "answer_newNT - answer_bothNT     -11.09  4.82\n",
       "answer_newNT - answer_nullmodel    8.53  4.02\n",
       "answer_bothNT - answer_nullmodel  19.61  6.94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# via leave-one-out crossvalidation\n",
    "comparison <- loo(answer_conNT, answer_newNT, answer_bothNT, answer_nullmodel, file=\"loo_modelcomp\")\n",
    "\n",
    "# WAIC\n",
    "#comparison <- waic(answer_conNT, answer_newNT, answer_bothNT, answer_nullmodel)\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve individual fit measures\n",
    "\n",
    "#comparison$answer_conNT\n",
    "#comparison$answer_conNT$looic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot(answer_newNT, ask = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only plot posteriors of standard deviation for parameters\n",
    "#plot(discmodel1, pars=\"^sd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of predictions\n",
    "#pp_check(answer_newNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prediction by marginalized effects\n",
    "#plot(marginal_effects(answer_newNT), ask = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "- the posterior standard deviation for the interaction parameters have most of the mass close to zero.\n",
    "            sd_sub__Block.Q:ED\n",
    "            sd_sub__Block.L:ED\n",
    "- This could indicate that letting them freely varying is not necessary or may even indicate overfitting. We should set up model(s) with these factors as only fixed effects and compare via LOO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "## Interpretability\n",
    "\n",
    "- Effect coding for categorical predictors (Block)\n",
    "\n",
    "## Hypothesis testing\n",
    "\n",
    "- Assess contrasts\n",
    "- Reduce model complexity and compare with LOO\n",
    "\n",
    "## Outlier evaluation\n",
    "\n",
    "- Compare models based on data including and excluding outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
